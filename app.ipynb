{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-v VIDEO] [-t TRACKER] [-s SLOW]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/yashasvi.ranjan/Library/Jupyter/runtime/kernel-fdcae4e7-b956-4160-a175-dbc558d8b68f.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yashasvi.ranjan/ultra/cv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-v\", \"--video\", type=str,\n",
    "                help=\"path to input video file\")\n",
    "ap.add_argument(\"-t\", \"--tracker\", type=str, default=\"kcf\",\n",
    "                help=\"OpenCV object tracker type\")\n",
    "ap.add_argument(\"-s\", \"--slow\", type=str, default=0,\n",
    "                help=\"OpenCV object tracker type\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# extract the OpenCV version info\n",
    "(major, minor) = cv2.__version__.split(\".\")[:2]\n",
    "\n",
    "# if we are using OpenCV 3.2 OR BEFORE, we can use a special factory\n",
    "# function to create our object tracker\n",
    "if int(major) == 3 and int(minor) < 3:\n",
    "    tracker = cv2.Tracker_create(args[\"tracker\"].upper())\n",
    "\n",
    "# otherwise, for OpenCV 3.3 OR NEWER, we need to explicity call the\n",
    "# approrpiate object tracker constructor:\n",
    "else:\n",
    "    # initialize a dictionary that maps strings to their corresponding\n",
    "    # OpenCV object tracker implementations\n",
    "    OPENCV_OBJECT_TRACKERS = {\n",
    "        \"csrt\": cv2.TrackerCSRT_create,\n",
    "        \"kcf\": cv2.TrackerKCF_create,\n",
    "        \"boosting\": cv2.TrackerBoosting_create,\n",
    "        \"mil\": cv2.TrackerMIL_create,\n",
    "        \"tld\": cv2.TrackerTLD_create,\n",
    "        \"medianflow\": cv2.TrackerMedianFlow_create,\n",
    "        \"mosse\": cv2.TrackerMOSSE_create\n",
    "    }\n",
    "\n",
    "    # grab the appropriate object tracker using our dictionary of\n",
    "    # OpenCV object tracker objects\n",
    "    tracker = OPENCV_OBJECT_TRACKERS[args[\"tracker\"]]()\n",
    "\n",
    "# initialize the bounding box coordinates of the object we are going\n",
    "# to track\n",
    "initBB = None\n",
    "\n",
    "# if a video path was not supplied, grab the reference to the web cam\n",
    "if not args.get(\"video\", False):\n",
    "    print(\"[INFO] starting video stream...\")\n",
    "    vs = VideoStream(src=0).start()\n",
    "    time.sleep(1.0)\n",
    "\n",
    "# otherwise, grab a reference to the video file\n",
    "else:\n",
    "    vs = cv2.VideoCapture(args[\"video\"])\n",
    "\n",
    "# initialize the FPS throughput estimator\n",
    "fps = None\n",
    "\n",
    "# loop over frames from the video stream\n",
    "isRecording = True\n",
    "sleepTime = int(args[\"slow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c26efa4b9824>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# grab the current frame, then handle if we are using a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# VideoStream or VideoCapture object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisplayFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-c26efa4b9824>\u001b[0m in \u001b[0;36mdisplayFrame\u001b[0;34m(flag)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"next\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"prev\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vs' is not defined"
     ]
    }
   ],
   "source": [
    "def displayFrame(flag=\"next\"):\n",
    "    ret = None\n",
    "    frame = None\n",
    "    if flag == \"next\":\n",
    "        ret, frame = vs.read()\n",
    "\n",
    "    if flag == \"prev\":\n",
    "        next_frame = vs.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "        current_frame = next_frame - 1\n",
    "        previous_frame = current_frame - 1\n",
    "        vs.set(cv2.CAP_PROP_POS_FRAMES, previous_frame)\n",
    "        ret, frame = vs.read()\n",
    "\n",
    "    if flag == \"cur\":\n",
    "        next_frame = vs.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "        current_frame = next_frame - 1\n",
    "        vs.set(cv2.CAP_PROP_POS_FRAMES, current_frame)\n",
    "        ret, frame = vs.read()\n",
    "\n",
    "    if not ret:\n",
    "        return None\n",
    "    # check to see if we have reached the end of the stream\n",
    "    if frame is None:\n",
    "        return None\n",
    "\n",
    "    # resize the frame (so we can process it faster) and grab the\n",
    "    # frame dimensions\n",
    "    frame = imutils.resize(frame, width=500)\n",
    "    (H, W) = frame.shape[:2]\n",
    "\n",
    "    # check to see if we are currently tracking an object\n",
    "    if initBB is not None:\n",
    "        # grab the new bounding box coordinates of the object\n",
    "        (success, box) = tracker.update(frame)\n",
    "\n",
    "        # check to see if the tracking was a success\n",
    "        if success:\n",
    "            (x, y, w, h) = [int(v) for v in box]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h),\n",
    "                          (0, 255, 0), 2)\n",
    "\n",
    "        # update the FPS counter\n",
    "        fps.update()\n",
    "        fps.stop()\n",
    "\n",
    "        # initialize the set of information we'll be displaying on\n",
    "        # the frame\n",
    "        info = [\n",
    "            (\"Tracker\", args[\"tracker\"]),\n",
    "            (\"Success\", \"Yes\" if success else \"No\"),\n",
    "            (\"FPS\", \"{:.2f}\".format(fps.fps())),\n",
    "            (\"Cords\", \"(\"+str(x)+\",\"+str(y)+\")\")\n",
    "        ]\n",
    "\n",
    "        # loop over the info tuples and draw them on our frame\n",
    "        for (i, (k, v)) in enumerate(info):\n",
    "            text = \"{}: {}\".format(k, v)\n",
    "            cv2.putText(frame, text, (10, H - ((i * 20) + 20)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "    # show the output frame\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    return frame\n",
    "\n",
    "\n",
    "while True:\n",
    "    # grab the current frame, then handle if we are using a\n",
    "    # VideoStream or VideoCapture object\n",
    "    frame = displayFrame()\n",
    "    if frame is None:\n",
    "        break\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # if the 's' key is selected, we are going to \"select\" a bounding\n",
    "    # box to track\n",
    "    if key == ord(\"s\"):\n",
    "            # select the bounding box of the object we want to track (make\n",
    "            # sure you press ENTER or SPACE after selecting the ROI)\n",
    "        initBB = cv2.selectROI(\"frame\", frame, fromCenter=False,\n",
    "                               showCrosshair=True)\n",
    "\n",
    "        # start OpenCV object tracker using the supplied bounding box\n",
    "        # coordinates, then start the FPS throughput estimator as well\n",
    "        tracker.init(frame, initBB)\n",
    "        fps = FPS().start()\n",
    "\n",
    "    elif key == ord(\"x\"):\n",
    "        while True:\n",
    "            key2 = cv2.waitKey(1) or 0xff\n",
    "            if frame is None:\n",
    "                exit()\n",
    "            cv2.imshow('frame', frame)\n",
    "            if key2 == ord('x'):\n",
    "                break\n",
    "            elif key2 == ord(\"n\"):\n",
    "                frame = displayFrame()\n",
    "\n",
    "            elif key2 == ord(\"p\"):\n",
    "                frame = displayFrame(\"prev\")\n",
    "\n",
    "            elif key2 == ord(\"s\"):\n",
    "                        # select the bounding box of the object we want to track (make\n",
    "                    # sure you press ENTER or SPACE after selecting the ROI)\n",
    "                initBB = cv2.selectROI(\"frame\", frame, fromCenter=False,\n",
    "                                       showCrosshair=True)\n",
    "\n",
    "                # start OpenCV object tracker using the supplied bounding box\n",
    "                # coordinates, then start the FPS throughput estimator as well\n",
    "                tracker.init(frame, initBB)\n",
    "                fps = FPS().start()\n",
    "                frame = displayFrame(\"cur\")\n",
    "\n",
    "            elif key2 == ord(\"q\"):\n",
    "                exit()\n",
    "\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "    elif key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "    elif key == ord(\"d\"):\n",
    "        sleepTime = sleepTime - 1 if sleepTime > 0 else sleepTime\n",
    "\n",
    "    elif key == ord(\"i\"):\n",
    "        sleepTime = sleepTime + 1\n",
    "\n",
    "    time.sleep(sleepTime)\n",
    "\n",
    "# if we are using a webcam, release the pointer\n",
    "if not args.get(\"video\", False):\n",
    "    vs.stop()\n",
    "\n",
    "# otherwise, release the file pointer\n",
    "else:\n",
    "    vs.release()\n",
    "\n",
    "# close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
